# **Amazon Glue + Athena + S3: Serverless Data Lake Querying**

Amazon **Glue** and **Athena** together form the backbone of AWS’s **serverless data lake querying** architecture.  
They let you:

- Discover schema from S3 data (Glue Crawlers)
    
- Store and manage metadata (Glue Data Catalog)
    
- Run SQL queries directly on S3 (Athena)
    
- Build ETL pipelines using Glue Jobs later
    

---

## **3.1 The Glue–Athena–S3 Relationship**

Before diving into commands, let’s connect the three services conceptually:

|Layer|Service|Purpose|
|---|---|---|
|**Storage Layer**|Amazon S3|Stores raw, intermediate, and gold data as objects|
|**Metadata Layer**|AWS Glue Data Catalog|Central repository for table definitions, schema, and partitions|
|**Query Layer**|Amazon Athena|SQL engine that reads from the Glue Catalog and queries S3 data directly|

Think of Glue Data Catalog as a **“database of metadata”** — it doesn’t store data, only the structure and location of data files in S3.  
Athena then uses this metadata to treat S3 like a SQL database.

---

## **3.2 AWS Glue Data Catalog: Core Concepts**

### **What It Is**

- A fully managed **metadata repository**.
    
- Stores **databases**, **tables**, **partitions**, and **connections**.
    
- Acts as the metadata layer for:
    
    - **Athena**
        
    - **Redshift Spectrum**
        
    - **EMR**
        
    - **Glue Jobs**
        

### **Why It’s Needed**

S3 stores files, but has **no schema** — Glue provides schema-on-read.  
That means you don’t define structure when writing; you define it **when reading** using the Catalog.

### **Core Components**

|Component|Description|
|---|---|
|**Database**|Logical container for related tables|
|**Table**|Schema and location info for data files (CSV, JSON, Parquet, etc.)|
|**Partition**|Subdivision of table data (e.g., by date, region, etc.)|
|**Crawler**|Automatically infers schema and creates/updates tables|
|**Classifier**|Defines how files are interpreted (CSV, JSON, etc.)|
|**Connection**|Details for connecting to data sources like RDS or JDBC|

---

## **3.3 Creating Glue Databases (CLI)**

A **Glue Database** groups related tables — think of it like a schema in a SQL database.

```bash
aws glue create-database --database-input Name=mydata.catalog
```

To verify:

```bash
aws glue get-databases
```

If you need to delete a database:

```bash
aws glue delete-database --name mydata.catalog
```

✅ **Note:** You can also do this in the Console under Glue → Data Catalog → Databases.

---

## **3.4 Glue Tables**

Glue Tables describe:

- **Location:** S3 path
    
- **Format:** CSV, JSON, Parquet, etc.
    
- **Columns and types**
    
- **Partition keys**
    
- **Serde info:** How data is serialized/deserialized
    

You can create tables manually (for learning), but in real pipelines, **crawlers** do it automatically.

---

## **3.5 Crawlers: Automatic Schema Discovery**

Glue **Crawlers** are the bridge between raw S3 files and the Glue Data Catalog.  
They:

- Scan the S3 prefix (e.g. `s3://developers-test-bucket1/raw/`)
    
- Identify data format (CSV/JSON/Parquet)
    
- Infer schema (column names, types)
    
- Create or update tables in your Catalog
    

### **Steps (Console or CLI)**

1. **Create crawler**
    
    - Data store: S3
        
    - Path: `s3://developers-test-bucket1/raw/`
        
    - IAM Role: e.g. `AWSGlueServiceRole`
        
    - Output: Glue database (e.g., `sourcesCatalogue`)
        
2. **Run crawler**
    
    - Logs appear under “Runs” in the console
        
    - New tables appear in “Tables” under your chosen database
        
3. **Result**
    
    - Each table shows: columns, partitions, file format, and S3 location.
        

---

## **3.6 Crawlers vs Manual Tables**

|Feature|Manual Table|Crawler|
|---|---|---|
|Schema definition|User-provided|Auto-inferred|
|Partition detection|Manual|Automatic|
|Maintenance|Manual updates|Auto-updates when re-run|
|Best for|Static data|Evolving data lakes|

**In production:** You’ll typically have scheduled crawlers running after new data is ingested into S3.

---

## **3.7 Athena: Querying S3 via Glue**

### **What Athena Is**

Amazon Athena is a **serverless, pay-per-query SQL engine** built on top of **Presto/Trino**.  
It reads data directly from S3 using schemas from Glue.

You only pay for **data scanned**, so optimizing file formats and partitioning directly affects cost and speed.

---

## **3.8 Setting Up Athena**

### **Step 1: Set Query Result Location**

Athena must write query results to an S3 bucket:

```bash
aws athena start-query-execution \
  --query-string "SELECT 1" \
  --query-execution-context Database=sourcescatalogue \
  --result-configuration OutputLocation=s3://developers-test-bucket1/query-results/
```

### **Step 2: Run SQL Queries**

In Athena Query Editor (or via CLI):

```sql
USE sourcescatalogue;
SELECT * FROM flights LIMIT 10;
```

To count rows grouped by date:

```bash
aws athena start-query-execution \
  --query-string "SELECT count(*), fl_date FROM flights GROUP BY fl_date ORDER BY fl_date DESC LIMIT 25" \
  --query-execution-context Database=sourcescatalogue \
  --result-configuration OutputLocation=s3://developers-test-bucket1/mongoDocs/
```

---

## **3.9 Athena Query Examples**

|Query|Purpose|
|---|---|
|`SELECT * FROM table LIMIT 10;`|Preview data|
|`SELECT COUNT(*) FROM table;`|Count rows|
|`SELECT region, COUNT(*) FROM sales GROUP BY region;`|Aggregation|
|`SELECT * FROM table WHERE date='2023-10-01';`|Partition pruning|
|`MSCK REPAIR TABLE table_name;`|Update Glue partitions after adding new S3 folders|

---

## **3.10 Partitions and Performance**

Partitions are **logical subdirectories** in S3 like:

```
s3://developers-test-bucket1/raw/date=2023-10-01/
```

Athena uses these to **read only relevant files**, improving cost and performance.

If you add new data manually, refresh partitions with:

```sql
MSCK REPAIR TABLE flights;
```

Or re-run the crawler to detect new partitions.

---

## **3.11 Deep Dive: Partitioning in Athena**

Partitioning is one of the **most critical performance and cost optimization techniques** in Athena and Glue.

### **3.11.1 What It Is**

A partition is a logical division of a dataset, typically based on columns such as date, region, or user ID.  
It corresponds to **folder structures in S3**, following the pattern `key=value/`.

Example:

```
s3://sales-data/
    year=2023/month=01/
    year=2023/month=02/
    year=2024/month=01/
```

When you query:

```sql
SELECT * FROM sales WHERE year='2024' AND month='01';
```

Athena will only scan files under `year=2024/month=01/` — skipping the rest.

Without partitioning, Athena scans **all files**, leading to slower queries and higher costs.

---

### **3.11.2 How It Works Internally**

- Glue Catalog stores partition metadata (key–value mapping to folder paths).
    
- Athena reads the metadata and determines which subfolders to query.
    
- Only those S3 prefixes are accessed, minimizing data scanned.
    

Each partition entry in Glue has:

- Partition column values (`year=2024`, `month=01`)
    
- The S3 location (`s3://sales-data/year=2024/month=01/`)
    

---

### **3.11.3 Setting Up Partitioning**

#### **Option 1: Define During Table Creation**

If your data already follows a partitioned folder structure:

```sql
CREATE EXTERNAL TABLE sales (
  order_id STRING,
  amount DOUBLE
)
PARTITIONED BY (year STRING, month STRING)
STORED AS PARQUET
LOCATION 's3://sales-data/';
```

Athena expects folders like `year=YYYY/month=MM/`.

After creation, load partition metadata with:

```sql
MSCK REPAIR TABLE sales;
```

---

#### **Option 2: Glue Crawler Auto-Detection**

- Crawlers automatically detect folder patterns like `key=value/`.
    
- They add partition columns and keep them updated on re-runs.
    

✅ Ideal for dynamic, evolving data lakes.

---

#### **Option 3: Add Partitions Manually Later**

You can add partitions even after table creation.

```sql
ALTER TABLE sales ADD PARTITION (year='2024', month='01')
LOCATION 's3://sales-data/year=2024/month=01/';
```

Or discover all missing partitions in bulk:

```sql
MSCK REPAIR TABLE sales;
```

This recursively scans the folder structure and registers all partitions.

---

### **3.11.4 Prerequisites**

- Folder structure must follow the `key=value/` format.
    
- Table must be external (i.e., created on S3).
    
- IAM permissions required:
    
    - `s3:GetObject`, `s3:ListBucket`
        
    - `glue:GetTable`, `glue:GetPartitions`
        
- Compatible formats: CSV, JSON, Parquet, ORC.
    
- Partition column names must match folder key names exactly.
    

---

### **3.11.5 Adding or Modifying Partitions**

- You **can** add new partitions anytime (`ALTER TABLE`, `MSCK REPAIR TABLE`).
    
- You **cannot** change partition column definitions without recreating the table.
    

---

### **3.11.6 Benefits**

|Benefit|Explanation|
|---|---|
|**Performance**|Athena skips irrelevant data folders|
|**Cost**|You pay only for data scanned|
|**Organization**|Easier lifecycle management (e.g., daily or monthly folders)|

Example:  
Unpartitioned query scans 500 GB → ₹ cost  
Partitioned query scans 40 GB → ~90% cheaper.

---

### **3.11.7 Best Practices**

|Scenario|Recommended Partition Key|Notes|
|---|---|---|
|Time-series data|`year`, `month`, `day`|Most common|
|Regional datasets|`country`, `state`|For location filtering|
|Large datasets|Multi-level partitions|Avoid small files per partition|
|Frequent updates|Use Glue crawler|Keeps partitions in sync|

---

### **3.11.8 When to Use Crawlers vs Manual Management**

|Use Case|Recommended Approach|
|---|---|
|Static / historical data|Manual partitions + `MSCK REPAIR TABLE`|
|Frequently updated data|Glue Crawler (scheduled)|
|Complex folder patterns|ETL script or custom registration|

---

## **3.12 Catalog Evolution (Schema Changes)**

When new columns appear in files:

- Re-run the crawler → Glue updates schema
    
- Athena immediately recognizes new schema
    
- Older queries still work if new columns are nullable
    

If schema diverges too much:

- Manually alter the Glue table, or
    
- Drop and recreate it.
    

---

## **3.13 Athena File Formats and Optimization**

|Format|Compression|Query Speed|Typical Use|
|---|---|---|---|
|**CSV**|None|Slow|Raw ingestion|
|**JSON**|None|Medium|Semi-structured logs|
|**Parquet**|Columnar|Very fast|Analytical queries|
|**ORC**|Columnar|Very fast|Similar to Parquet|

**Why Parquet Matters:**

- Columnar format → reads only required columns
    
- Highly compressed → less data scanned → cheaper queries
    
- Glue ETL Jobs (later) can convert raw CSV → Parquet
    

---

## **3.14 Glue Table Properties (Advanced)**

Each Glue table includes:

- `StorageDescriptor`: defines columns, location, file format, SerDe info
    
- `Parameters`: metadata like classification and compression
    
- `PartitionKeys`: columns used for partitioning
    

Example JSON (simplified):

```json
{
  "Name": "flights",
  "StorageDescriptor": {
    "Columns": [
      {"Name": "fl_date", "Type": "string"},
      {"Name": "origin", "Type": "string"}
    ],
    "Location": "s3://developers-test-bucket1/raw/flights/",
    "InputFormat": "org.apache.hadoop.mapred.TextInputFormat",
    "OutputFormat": "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat",
    "SerdeInfo": {
      "SerializationLibrary": "org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"
    }
  },
  "PartitionKeys": [{"Name": "date", "Type": "string"}]
}
```

---

## **3.15 Data Lifecycle in Context**

|Step|Service|Role|
|---|---|---|
|**1. Ingest raw data**|S3|Landing zone|
|**2. Discover schema**|Glue Crawler|Creates metadata|
|**3. Query data**|Athena|Serverless SQL|
|**4. Optimize schema**|Glue|Schema evolution|
|**5. Convert formats / ETL**|Glue Jobs (later)|Parquet/Delta conversion|
